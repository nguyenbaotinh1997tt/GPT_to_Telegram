import os
import json
import logging
import openai
import nest_asyncio
import re
import requests
import base64
from difflib import get_close_matches
from telegram import Update, Message
from telegram.constants import ParseMode
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    ContextTypes, filters
)
from dotenv import load_dotenv

# =====================[ Load bi·∫øn m√¥i tr∆∞·ªùng ]=====================
load_dotenv()
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

DEFAULT_SYSTEM_PROMPT = os.getenv("DEFAULT_SYSTEM_PROMPT", "You are ChatGPT, a helpful assistant.")

# =====================[ C·∫•u h√¨nh file & log ]=====================
CONV_FILE = "conversations.json"
DEVICE_FILE = "devices.json"
RENTAL_FILE = "rentals.json"
logging.basicConfig(level=logging.INFO)

# =====================[ Load/L∆∞u D·ªØ li·ªáu ]=====================
def load_json(path):
    return json.load(open(path, "r", encoding="utf-8")) if os.path.exists(path) else {}

def save_json(path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

conversation_histories = load_json(CONV_FILE)
devices = load_json(DEVICE_FILE)
rentals = load_json(RENTAL_FILE)

# =====================[ Helper: l∆∞u h·ªôi tho·∫°i ]=====================
def append_conversation(chat_id, role, content, user=None):
    if chat_id not in conversation_histories:
        conversation_histories[chat_id] = [{"role": "system", "content": DEFAULT_SYSTEM_PROMPT}]
    entry = {"role": role, "content": content}
    if user:
        entry["user"] = user
    conversation_histories[chat_id].append(entry)
    save_json(CONV_FILE, conversation_histories)

# =====================[ Helper: ki·ªÉm tra n·∫øu n√™n ph·∫£n h·ªìi GPT ]=====================
def should_respond_to(text):
    trigger_words = ["gpt", "tr·ª£ l√Ω", "chatgpt"]
    return any(re.search(rf"\b{re.escape(word)}\b", text.lower()) for word in trigger_words)

# =====================[ X·ª≠ l√Ω tin nh·∫Øn ·∫£nh + caption ]=====================
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    caption = message.caption or ""
    if not should_respond_to(caption):
        return

    try:
        photo = message.photo[-1]
        file = await context.bot.get_file(photo.file_id)
        response = requests.get(file.file_path)
        encoded_image = base64.b64encode(response.content).decode("utf-8")

        gpt_response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": [
                    {"type": "text", "text": caption or "Ph√¢n t√≠ch n·ªôi dung h√¨nh ·∫£nh."},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_image}"}}
                ]}
            ],
            max_tokens=500
        )
        reply = gpt_response.choices[0].message.content.strip()
        await message.reply_text(f"üì∏ {reply}")
    except Exception as e:
        logging.error(f"GPT Image Error: {e}")
        await message.reply_text("‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch ·∫£nh n√†y.")

# =====================[ X·ª≠ l√Ω tin nh·∫Øn vƒÉn b·∫£n th√¥ng minh ]=====================
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    chat_id = str(message.chat_id)
    text = message.text.strip()
    user = update.effective_user.username or update.effective_user.first_name
    lower = text.lower()

    # === Nh·∫≠n di·ªán th√™m thi·∫øt b·ªã v·ªõi s·ªë l∆∞·ª£ng ===
    add_match = re.search(r"(th√™m|ghi|c·∫≠p nh·∫≠t).*thi·∫øt b·ªã.*m√£ (\w+).*?l√† (.+?) v·ªõi s·ªë l∆∞·ª£ng (\d+)", lower)
    if add_match:
        device_id = add_match.group(2).upper()
        description = add_match.group(3).strip()
        quantity = int(add_match.group(4))
        devices[device_id] = {"desc": description, "qty": quantity, "rented": 0}
        save_json(DEVICE_FILE, devices)
        await message.reply_text(f"‚úÖ ƒê√£ l∆∞u thi·∫øt b·ªã `{device_id}`: {description} (s·ªë l∆∞·ª£ng: {quantity})", parse_mode=ParseMode.MARKDOWN)
        return

    # === Xem m√¥ t·∫£ thi·∫øt b·ªã ===
    if "thi·∫øt b·ªã" in lower and "l√† g√¨" in lower:
        found = [d for d in devices if d.lower() in lower]
        if found:
            reply = "\n".join([f"üì¶ `{d}`: {devices[d]['desc']} (SL: {devices[d].get('qty', '?')})" for d in found])
            await message.reply_text(reply, parse_mode=ParseMode.MARKDOWN)
        else:
            matches = get_close_matches(lower, devices.keys(), n=3, cutoff=0.6)
            if matches:
                await message.reply_text("‚ùì Kh√¥ng t√¨m th·∫•y thi·∫øt b·ªã ch√≠nh x√°c. C√≥ ph·∫£i b·∫°n mu·ªën h·ªèi v·ªÅ:\n" + "\n".join(matches))
            else:
                await message.reply_text("‚ùå Kh√¥ng t√¨m th·∫•y thi·∫øt b·ªã n√†o ph√π h·ª£p trong d·ªØ li·ªáu.")
        return

    # === Xem to√†n b·ªô thi·∫øt b·ªã ===
    if re.search(r"(danh s√°ch|xem|li·ªát k√™).*thi·∫øt b·ªã", lower):
        if devices:
            reply = "\n".join([f"üì¶ `{d}`: {info['desc']} (SL: {info.get('qty', '?')} - ƒêang thu√™: {info.get('rented', 0)})" for d, info in devices.items()])
            await message.reply_text(reply, parse_mode=ParseMode.MARKDOWN)
        else:
            await message.reply_text("‚ö†Ô∏è Hi·ªán ch∆∞a c√≥ thi·∫øt b·ªã n√†o ƒë∆∞·ª£c l∆∞u.")
        return

    # === Th·ªëng k√™ thi·∫øt b·ªã ƒëang r·∫£nh ===
    if re.search(r"(thi·∫øt b·ªã )?(r·∫£nh|c√≤n tr·ªëng|ch∆∞a thu√™)", lower):
        available = [
            f"‚úÖ `{d}`: {info['desc']} (C√≤n: {info.get('qty', 0) - info.get('rented', 0)})"
            for d, info in devices.items()
            if info.get("qty", 0) - info.get("rented", 0) > 0
        ]
        if available:
            await message.reply_text("üìä Thi·∫øt b·ªã c√≤n r·∫£nh:\n" + "\n".join(available), parse_mode=ParseMode.MARKDOWN)
        else:
            await message.reply_text("‚ùó Hi·ªán t·∫•t c·∫£ thi·∫øt b·ªã ƒë√£ ƒë∆∞·ª£c thu√™ h·∫øt.")
        return

    # === T√¨m theo ng∆∞·ªùi ho·∫∑c lo·∫°i ===
    find_match = re.search(r"(ai|ng∆∞·ªùi n√†o).*thu√™.*(\w+)|thi·∫øt b·ªã.*(\w+).*ƒë∆∞·ª£c.*(ai|ng∆∞·ªùi) thu√™", lower)
    if find_match:
        keyword = find_match.group(2) or find_match.group(3)
        if keyword:
            matched = [f"üì¶ `{d}`: {info['desc']} (SL: {info.get('qty', '?')})" for d, info in devices.items() if keyword.lower() in info['desc'].lower()]
            if matched:
                await message.reply_text("üîé K·∫øt qu·∫£ t√¨m th·∫•y:\n" + "\n".join(matched), parse_mode=ParseMode.MARKDOWN)
            else:
                suggestions = get_close_matches(keyword.lower(), [info['desc'].lower() for info in devices.values()], n=3, cutoff=0.6)
                if suggestions:
                    await message.reply_text("‚ùì Kh√¥ng t√¨m th·∫•y ch√≠nh x√°c. C√≥ ph·∫£i b·∫°n mu·ªën t√¨m:\n" + "\n".join(suggestions))
                else:
                    await message.reply_text("‚ùå Kh√¥ng t√¨m th·∫•y thi·∫øt b·ªã n√†o ph√π h·ª£p.")
        return

    # === Ghi nh·ªõ h·ªôi tho·∫°i GPT (ch·ªâ n·∫øu ch·ª©a t·ª´ kh√≥a) ===
    if not should_respond_to(lower):
        return

    append_conversation(chat_id, "user", text, user)
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{k: v for k, v in m.items() if k in ["role", "content"]} for m in conversation_histories[chat_id]],
            temperature=0.7,
        )
        reply = response.choices[0].message.content.strip()
        append_conversation(chat_id, "assistant", reply)
    except Exception as e:
        logging.error(f"GPT Text Error: {e}")
        reply = "‚ùå ƒê√£ x·∫£y ra l·ªói khi g·ªçi GPT."

    await message.reply_text(f"@{user} {reply}", parse_mode=ParseMode.MARKDOWN)

# =====================[ MAIN BOT ]=====================
async def main():
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", lambda u, c: u.message.reply_text("Bot ƒë√£ s·∫µn s√†ng.")))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_text))

    await app.run_polling()

if __name__ == '__main__':
    import asyncio
    nest_asyncio.apply()
    asyncio.run(main())
